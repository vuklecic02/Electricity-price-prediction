import os
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Input
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint


df = pd.read_csv("D:\\FON Cetvrta godina\\Neuronske mreže\\Projekat\\Austria.csv")


df.info()


df["utc_timestamp"] = pd.to_datetime(df["utc_timestamp"])


df = df.set_index("utc_timestamp").sort_index()


target = "AT_price_day_ahead"
df = df[~df[target].isna()] 


df["cet_cest_timestamp"] = pd.to_datetime(df["cet_cest_timestamp"], utc=True)
df["cet_cest_timestamp"] = df["cet_cest_timestamp"].dt.tz_convert("CET")  # CET/CEST
df["hour"] = df["cet_cest_timestamp"].dt.hour
df["dayofweek"] = df["cet_cest_timestamp"].dt.dayofweek  # 0=Monday
df["month"] = df["cet_cest_timestamp"].dt.month

df.drop(columns=["cet_cest_timestamp"], inplace=True)


df.info()


df = df.drop('Unnamed: 0', axis=1)

df_copy = df.copy()
df_copy[target] = df_copy[target].interpolate(method="time").ffill().bfill()


import matplotlib.pyplot as plt

plt.figure(figsize=(15,5))
plt.plot(df.index, df[target], label="AT_price_day_ahead")
plt.title("Austria Day Ahead Price over Time")
plt.xlabel("Date")
plt.ylabel("Price")
plt.legend()
plt.show()


split_index = int(0.7 * len(df))
split_date = df.index[split_index]

train = df.loc[:split_date].copy()
test = df.loc[split_date:].copy()


features = ["hour", "dayofweek", "month",
            "AT_solar_generation_actual", 
            "AT_wind_onshore_generation_actual",
            "AT_load_forecast_entsoe_transparency",
            "AT_load_actual_entsoe_transparency"]


train[target] = train[target].interpolate(method="time").ffill().bfill()


train.head()


from statsmodels.tsa.seasonal import seasonal_decompose

# Pretpostavljamo da je frekvencija satna: za 15-minutni interval, koristimo period=96 (24h * 4)
decompose_period = 96  # ako je 15-min interval i želimo dnevnu sezonalnost
short_period = df_copy['2018-01-01':'2018-01-07'][target]
result = seasonal_decompose(short_period, model='additive', period=decompose_period)

# Plot komponenti
plt.figure(figsize=(20,6))
result.plot()
plt.xticks(rotation=45)
plt.suptitle("Seasonal Decomposition of AT_price_day_ahead", fontsize=16, y=1.05)
plt.show()


monthly_avg = df[target].resample('ME').mean()
plt.figure(figsize=(15,5))
monthly_avg.plot()
plt.title("Monthly Average Price")
plt.ylabel("Price")
plt.show()

plt.figure(figsize=(10,5))
df.boxplot(column=target, by="hour")
plt.title("Price Distribution by Hour of Day")
plt.suptitle("")
plt.xlabel("Hour")
plt.ylabel("Price")
plt.show()


from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

plt.figure(figsize=(12,4))
plot_acf(df[target].dropna(), lags=96, ax=plt.gca())
plt.title("Autocorrelation (ACF) - up to 96 lags")
plt.show()

plt.figure(figsize=(12,4))
plot_pacf(df[target].dropna(), lags=96, ax=plt.gca())
plt.title("Partial Autocorrelation (PACF) - up to 96 lags")
plt.show()



test[target] = test[target].interpolate(method="time").ffill().bfill()


import seaborn as sns

plt.figure(figsize=(6,4))
sns.boxplot(y=train[target])
plt.title("Boxplot target promenljive")
plt.show()

# Outlier detekcija i winsorizacija targeta
Q1 = train[target].quantile(0.25)
Q3 = train[target].quantile(0.75)
IQR = Q3 - Q1

# Granice za outliere
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

print(f"Outlier granice: {lower_bound:.2f}, {upper_bound:.2f}")

outliers = train[target][(train[target] < lower_bound) | (train[target] > upper_bound)]
print(f"Broj outlayera u targetu: {len(outliers)}")

# Winsorizacija (odsecanje na 5% i 95% percentil)
low_clip = train[target].quantile(0.05)
high_clip = train[target].quantile(0.95)

train[target] = train[target].clip(lower=low_clip, upper=high_clip)

plt.figure(figsize=(6,4))
sns.boxplot(y=train[target])
plt.title("Boxplot target promenljive (posle winsorizacije)")
plt.show()


num_features = [
    "AT_solar_generation_actual",
    "AT_wind_onshore_generation_actual",
    "AT_load_forecast_entsoe_transparency",
    "AT_load_actual_entsoe_transparency"
]

corr_matrix = train[num_features].corr()

plt.figure(figsize=(6,4))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Korelacija između numeričkih feature-a")
plt.show()

def drop_highly_correlated(train, test, target, features, 
                           high_corr_threshold=0.9, min_target_corr=0.3,
                           keep_features=["hour","dayofweek","month"]):
    corr_matrix = train[features].corr()
    to_drop = set()

    # Visoko korelisani parovi
    for i in range(len(features)):
        for j in range(i+1, len(features)):
            f1, f2 = features[i], features[j]
            corr = corr_matrix.loc[f1, f2]
            if abs(corr) > high_corr_threshold:
                # Koja je veća korelacija sa targetom?
                corr_f1 = abs(train[[f1, target]].corr().iloc[0,1])
                corr_f2 = abs(train[[f2, target]].corr().iloc[0,1])
                if corr_f1 < corr_f2:
                    to_drop.add(f1)
                else:
                    to_drop.add(f2)
                print(f"Visoko korelisani: {f1}-{f2} ({corr:.3f}) - {'f1' if corr_f1 < corr_f2 else 'f2'}")

    # Feature-i sa malom korelacijom sa targetom
    for f in features:
        if f in keep_features:
            continue
        corr_with_target = abs(train[[f, target]].corr().iloc[0,1])
        if corr_with_target < min_target_corr:
            to_drop.add(f)
            print(f"Niska korelacija sa targetom: {f} ({corr_with_target:.3f}) ")

    # Drop iz train i test
    train = train.drop(columns=list(to_drop), errors="ignore")
    test  = test.drop(columns=list(to_drop), errors="ignore")

    # Ažuriramo listu feature-a
    features = [f for f in features if f not in to_drop]

    return train, test, features


train, test, features = drop_highly_correlated(train, test, target, features, high_corr_threshold=0.8, min_target_corr=0.3, keep_features=["hour","dayofweek","month"])

plot_features = [f for f in features if f not in ["hour","dayofweek","month"]]
# Heatmap korelacija nakon uklanjanja visoko korelisanih
plt.figure(figsize=(8,6))
sns.heatmap(train[plot_features + [target]].corr(), annot=True, cmap="coolwarm", vmin=-1, vmax=1)
plt.title("Korelacija feature-a sa targetom (posle uklanjanja visoko korelisanih)")
plt.show()


scaler_y = MinMaxScaler()
scaler_X = MinMaxScaler()


# Skaliranje target-a
y_train_scaled = scaler_y.fit_transform(train[[target]])
y_test_scaled = scaler_y.transform(test[[target]])


# Ukoliko postoje na vrednosti
for col in features:
    train[col] = train[col].ffill().bfill()
    test[col] = test[col].ffill().bfill()


# Skaliranje ostalih atributa
X_train_scaled = scaler_X.fit_transform(train[features])
X_test_scaled = scaler_X.transform(test[features])


train.isna().sum()


test.isna().sum()


def create_sequences(y, X, look_back=24):
    X_seq, y_seq = [], []
    for i in range(len(y) - look_back):
        seq_y = y[i:i+look_back]
        feat = X[i+look_back]
        X_seq.append(np.hstack([seq_y.flatten(), feat]))
        y_seq.append(y[i+look_back])
    return np.array(X_seq), np.array(y_seq)


look_back = 24
X_train_seq, y_train_seq = create_sequences(y_train_scaled, X_train_scaled, look_back)
X_test_seq, y_test_seq = create_sequences(y_test_scaled, X_test_scaled, look_back)

# Preoblikovanje u 3D za RNN
X_train_seq = X_train_seq.reshape(X_train_seq.shape[0], look_back + X_train_scaled.shape[1], 1)
X_test_seq = X_test_seq.reshape(X_test_seq.shape[0], look_back + X_test_scaled.shape[1], 1)

print("Train shape:", X_train_seq.shape, y_train_seq.shape)
print("Test shape:", X_test_seq.shape, y_test_seq.shape)


#Pravljenje lstm modela
def build_lstm(input_shape, units=64):
    model = Sequential([
        Input(shape=input_shape),
        LSTM(units, return_sequences=False),
        Dropout(0.2),
        Dense(1)
    ])
    model.compile(optimizer="adam", loss="mse", metrics=["mae"])
    return model


lstm = build_lstm((X_train_seq.shape[1], X_train_seq.shape[2]))

# Early stopping callback
es = EarlyStopping(monitor="val_loss", patience=3, restore_best_weights=True)


history = lstm.fit(
    X_train_seq, y_train_seq,
    validation_data=(X_test_seq, y_test_seq),
    epochs=30,
    batch_size=64,
    callbacks=[es],
    verbose=1
)

# Plot train vs validation loss
plt.figure(figsize=(10, 6))
plt.plot(history.history["loss"], label="Train Loss", linewidth=2)
plt.plot(history.history["val_loss"], label="Validation Loss", linewidth=2)
plt.title("LSTM Loss tokom treniranja")
plt.xlabel("Epochs")
plt.ylabel("MSE Loss")
plt.legend()
plt.grid(True)
plt.show()



loss, mae = lstm.evaluate(X_test_seq, y_test_seq, verbose=0)
print(f"Test Loss: {loss:.4f}, Test MAE: {mae:.4f}")


y_pred_scaled = lstm.predict(X_test_seq)
y_pred = scaler_y.inverse_transform(y_pred_scaled)
y_true = scaler_y.inverse_transform(y_test_seq.reshape(-1,1))

plt.figure(figsize=(12,6))
plt.plot(y_true[:200], label="Prava cena")
plt.plot(y_pred[:200], label="Predikcija")
plt.legend()
plt.title("Uporedni prikaz stvarne i predviđene cene (prvih 200 sati)")
plt.show()


def build_gru(input_shape, units=64):
    model = Sequential([
        Input(shape=input_shape),
        GRU(units, return_sequences=False),
        Dropout(0.2),
        Dense(1)
    ])
    model.compile(optimizer="adam", loss="mse", metrics=["mae"])
    return model



gru = build_gru((X_train_seq.shape[1], X_train_seq.shape[2]))


history_gru = gru.fit(
    X_train_seq, y_train_seq,
    validation_data=(X_test_seq, y_test_seq),
    epochs=30,
    batch_size=64,
    callbacks=[es],
    verbose=1
)

plt.figure(figsize=(10, 6))
plt.plot(history_gru.history["loss"], label="Train Loss", linewidth=2)
plt.plot(history_gru.history["val_loss"], label="Validation Loss", linewidth=2)
plt.title("GRU Loss tokom treniranja")
plt.xlabel("Epochs")
plt.ylabel("MSE Loss")
plt.legend()
plt.grid(True)
plt.show()


pred_gru_scaled = gru.predict(X_test_seq)
pred_gru_orig = scaler_y.inverse_transform(pred_gru_scaled)
y_true = scaler_y.inverse_transform(y_test_seq.reshape(-1,1))

plt.figure(figsize=(12,6))
plt.plot(y_true[:200], label="True")
plt.plot(pred_gru_orig[:200], label="GRU Predicted")
plt.legend()
plt.title("GRU Predictions vs True (first 200 test samples)")
plt.show()


from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Chain forward cross validation
n_splits = 5
tscv = TimeSeriesSplit(n_splits=n_splits)

def run_cv_rnn(model_builder, X, y, name="Model"):
    rmse_scores, mae_scores = [], []

    for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):
        print(f"\n===== Fold {fold} / {n_splits} =====")

        X_train_fold, X_val_fold = X[train_idx], X[val_idx]
        y_train_fold, y_val_fold = y[train_idx], y[val_idx]

        # Nova instanca modela
        model = model_builder((X.shape[1], X.shape[2]))

        es = EarlyStopping(monitor="val_loss", patience=3, restore_best_weights=True)

        model.fit(
            X_train_fold, y_train_fold,
            validation_data=(X_val_fold, y_val_fold),
            epochs=30,
            batch_size=64,
            callbacks=[es],
            verbose=0
        )

        # Predikcija
        y_val_pred_scaled = model.predict(X_val_fold)
        y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled)
        y_val_true = scaler_y.inverse_transform(y_val_fold.reshape(-1, 1))

        # Metričke vrednosti
        rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred))
        mae = mean_absolute_error(y_val_true, y_val_pred)

        rmse_scores.append(rmse)
        mae_scores.append(mae)

        print(f"{name} Fold {fold} -> RMSE: {rmse:.4f}, MAE: {mae:.4f}")

    print(f"\n{name} Average RMSE: {np.mean(rmse_scores):.4f}, Average MAE: {np.mean(mae_scores):.4f}")


print("\n### LSTM Chain Forward CV ###")
run_cv_rnn(build_lstm, X_train_seq, y_train_seq, name="LSTM")

print("\n### GRU Chain Forward CV ###")
run_cv_rnn(build_gru, X_train_seq, y_train_seq, name="GRU")



